{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clickstream Clustering using Weighted Longest Common Subsequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is scientific article implementation: Arindam Banerjee and Joydeep Ghosh, _Clickstream Clustering Using Weighted Longest Common Subsequences_, (2001) [link here](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.135.9092).\n",
    "\n",
    "The implementation is divided into 3 parts:\n",
    "* First, paths similarity measure is calculated for all paths\n",
    "* Second, similarity graph is constructed\n",
    "* Third, graph partitioning algorithm is executed\n",
    "\n",
    "As it was impossible to get the same as in article data from [www.sulekha.com](https://www.sulekha.com), the weblogs from [www.bodyworlds.nl](https://www.bodyworlds.nl/nl) were considered instead. This choice is temporal, and data from e.g. NASA Kennedy Space Center [www.ita.ee.lbl.gov](http://ita.ee.lbl.gov/html/contrib/NASA-HTTP.html) should be used instead as those are the classical choice for web mining applications. The [www.bodyworlds.nl](https://www.bodyworlds.nl/nl) was chosen as these weblogs require minimum initial preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://github.com/man1/Python-LCS\n",
    "# get the matrix of LCS lengths at each sub-step of the recursive process\n",
    "# (m+1 by n+1, where m=len(list1) & n=len(list2) ... it's one larger in each direction \n",
    "# so we don't have to special-case the x-1 cases at the first elements of the iteration\n",
    "def lcs_mat(list1, list2):\n",
    "    m = len(list1)\n",
    "    n = len(list2)\n",
    "    # construct the matrix, of all zeroes\n",
    "    mat = [[0] * (n+1) for row in range(m+1)]\n",
    "    # populate the matrix, iteratively\n",
    "    for row in range(1, m+1):\n",
    "        for col in range(1, n+1):\n",
    "            if list1[row - 1] == list2[col - 1]:\n",
    "                # if it's the same element, it's one longer than the LCS of the truncated lists\n",
    "                mat[row][col] = mat[row - 1][col - 1] + 1\n",
    "            else:\n",
    "                # they're not the same, so it's the the maximum of the lengths of the LCSs of the two options (different list truncated in each case)\n",
    "                mat[row][col] = max(mat[row][col - 1], mat[row - 1][col])\n",
    "    # the matrix is complete\n",
    "    return mat\n",
    "\n",
    "# backtracks all the LCSs through a provided matrix\n",
    "def all_lcs(lcs_dict, mat, list1, list2, index1, index2):\n",
    "    #calculate recursively\n",
    "    if (index1 == 0) or (index2 == 0): # base case\n",
    "        return [[]]\n",
    "    elif list1[index1 - 1] == list2[index2 - 1]:\n",
    "        # elements are equal! Add it to all LCSs that pass through these indices\n",
    "        lcs_dict[(index1, index2)] = [prevs + [list1[index1 - 1]] for prevs in all_lcs(lcs_dict, mat, list1, list2, index1 - 1, index2 - 1)]\n",
    "        return lcs_dict[(index1, index2)]\n",
    "    else:\n",
    "        lcs_list = [] # set of sets of LCSs from here\n",
    "        # not the same, so follow longer path recursively\n",
    "        if mat[index1][index2 - 1] >= mat[index1 - 1][index2]:\n",
    "            before = all_lcs(lcs_dict, mat, list1, list2, index1, index2 - 1)\n",
    "            for series in before: # iterate through all those before\n",
    "                if not series in lcs_list: lcs_list.append(series) # and if it's not already been found, append to lcs_list\n",
    "        if mat[index1 - 1][index2] >= mat[index1][index2 - 1]:\n",
    "            before = all_lcs(lcs_dict, mat, list1, list2, index1 - 1, index2)\n",
    "            for series in before:\n",
    "                if not series in lcs_list: lcs_list.append(series)\n",
    "        lcs_dict[(index1, index2)] = lcs_list\n",
    "        return lcs_list\n",
    "\n",
    "# return a set of the sets of longest common subsequences in list1 and list2\n",
    "def lcs(list1, list2):\n",
    "    # mapping of indices to list of LCSs, so we can cut down recursive calls enormously\n",
    "    mapping = dict()\n",
    "    return all_lcs(mapping, lcs_mat(list1, list2), list1, list2, len(list1), len(list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return filtered subsequences with time\n",
    "def time_lcs(subsequence, list_of_dict):\n",
    "    return list(filter(lambda x : x['path'] in subsequence, list_of_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute composed similarity measure\n",
    "def similarity(list_of_dict1, list_of_dict2):\n",
    "    paths_list1 = map(lambda x : x['path'], list_of_dict1) \n",
    "    paths_list2 = map(lambda x : x['path'], list_of_dict2) \n",
    "    \n",
    "    page_subsequence = lcs(paths_list1, paths_list2)\n",
    "    time_subsequence1 = time_lcs(page_subsequence, list_of_dict1)\n",
    "    time_subsequence2 = time_lcs(page_subsequence, list_of_dict2)\n",
    "    \n",
    "    return s_similarity(time_subsequence1, time_subsequence2) * s_importance(time_subsequence1, time_subsequence2)\n",
    "\n",
    "# compute similarity component\n",
    "def s_similarity(l_alpha, l_beta):\n",
    "    return\n",
    "\n",
    "# compute importance component\n",
    "def s_importance(l_alpha, l_beta):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
